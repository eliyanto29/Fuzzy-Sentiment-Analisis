{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Fuzzy Sentiment Analysis RNN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eliyanto29/Fuzzy-Sentiment-Analisis/blob/master/Fuzzy_Sentiment_Analysis_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrmekYqERNfs",
        "colab_type": "text"
      },
      "source": [
        "#**Fuzzy Sentiment Analysis with an RNN**\n",
        "*Mathematics Department, Universitas Ahmad Dahlan, Indonesia*\n",
        "\n",
        "https://math.uad.ac.id/\n",
        "\n",
        "**Author**  : Sugiyarto, Ph.D dan Joko Eliyanto, S.Si\n",
        "\n",
        "**Email**  : joko1400015006@webmail.uad.ac.id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XrlHGCWRNf0",
        "colab_type": "text"
      },
      "source": [
        "### Abstraksi\n",
        "\n",
        "\n",
        "Sentimen analisis adalah salah satu bagian dari natural language processing. Analisis sentimen dapat dilakukan dengan berbasis kamus, atau berbasis machine learning. Analisis sentimen berbasis machine learning memiliki kelebihan kedinamisan untuk bertemu dengan dataset bahasa baru atau kosa kata baru.  Analisis sentimen berusaha untuk memahami sentimen yang terkandung dalam suatu kalimat. Sebuah kalimat bisa memiliki sentimen positif, netral atau negatif. Meskipun demikian, faktanya setiap kalimat tidak selalu bersentimen positif, negatif, atau netral secara jelas. Kami berusaha mengembangkan metode sentimen analisis yang dapat menunjukkan derajat sentimen suatu kalimat. Sentimen analisis fuzzy recurrent neural network diperkenalkan dalam makalah ini untuk menghasilkan hasil analisis sentimen yang lebih akurat. Recurrent neural network adalah metode machine learning yang popular untuk sentimen analisis. Konsep himpunan fuzzy digunakan untuk menyatakan derajat sentimen sebuah kalimat. Analisis jarak euclidean untuk menentukan kedekatan dua buah vektor digunakan untuk menunjukkan bahwa metode ini lebih baik dari metode standar. Metode yang kami ajukan berhasil menghasilkan sebuah nilai yang menunjukkan derajat sentimen sebuah kalimat. Perbandingan jarak euclid antara hasil sentimen analisis standar dan metode kami menunjukkan bahwa hasil fuzzy recurrent neural network memiliki jarak yang relatif dekat dengan nilai sentimen sesungguhnya. Sentimen analisis fuzzy recurrent neural network terbukti dapat menghasilkan hasil sentimen analisis yang lebih halus daripada metode standar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHV9g0X3RNf3",
        "colab_type": "text"
      },
      "source": [
        "### Import Modul"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo5h0FaaRNf5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, LSTM, Embedding, Dropout\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyL-xvRkRNgK",
        "colab_type": "text"
      },
      "source": [
        "### Mengakses dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlQOuoHFSsh6",
        "colab_type": "text"
      },
      "source": [
        "Dataset Tweet Airline\n",
        "\n",
        "Dataset ini berisi tweet terhadap pelayanan @USAmericanairlines. Kita diminta mengklasifikasikan tweet positif, negatif, dan netral, diikuti dengan mengkategorikan alasan negatif (seperti \"penerbangan terlambat\" atau \"layanan kasar\").\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzCqmd7IUUbS",
        "colab_type": "text"
      },
      "source": [
        "Membuka dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STsgbJieUNut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Membuka akses ke google drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhzDxaiXRNgL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mengakses dataset\n",
        "data = pd.read_csv('/content/gdrive/My Drive/SA DATASET/Tweets.csv')\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1kW_4DZRNgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Menghapus semua kolom kecuali kolom airline_sentiment dan teks.\n",
        "data = data[['airline_sentiment', 'text']]\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0i0d4DXRNg6",
        "colab_type": "text"
      },
      "source": [
        "### Data Eksplorasi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mGNV5YSRNg9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Menghitung jumlah sentiment\n",
        "data['airline_sentiment'].value_counts().sort_index().plot.bar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgJ_jYXeRNhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Menghitung jumlah teks\n",
        "data['text'].str.len().plot.hist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msgbogWmRNhj",
        "colab_type": "text"
      },
      "source": [
        "### Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRCS-wKFRNhm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Menghapus kata @VirginAmerica\n",
        "data['text'] = data['text'].str.replace('@VirginAmerica', '')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb0yA_FVRNh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Menghapus karakter yang tidak diinginkan\n",
        "data['text'].apply(lambda x: x.lower())\n",
        "data['text'] = data['text'].apply(lambda x: re.sub('[^a-zA-z0-9\\s]', '', x))\n",
        "data['text'].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9v63G0J5Vo-D",
        "colab_type": "text"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuH7u84BRNiA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tokenisasi kata-kata\n",
        "tokenizer = Tokenizer(num_words=5000, split=\" \")\n",
        "tokenizer.fit_on_texts(data['text'].values)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(data['text'].values)\n",
        "X = pad_sequences(X, maxlen=200, padding='post')\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuLFudO4RNjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mengkodekan sentimen negatif=[1 0 0], neutral=[0 1 0], dan positif=[0 0 1]\n",
        "y = pd.get_dummies(data['airline_sentiment']).values\n",
        "[print(data['airline_sentiment'][i], y[i]) for i in range(0,5)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVoZY2TzRNjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Memecah dataset menjadi data latih dan data uji\n",
        "#test_size: perbandingan data uji(0.2) dan data latih(0.8)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHFDcePnRNiL",
        "colab_type": "text"
      },
      "source": [
        "### Mendefinisikan Model RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBMtfraRRNio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mendefinisikan model RNN\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000, 256, input_length=X.shape[1]))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.2))\n",
        "model.add(LSTM(256, dropout=0.3, recurrent_dropout=0.2))\n",
        "model.add(Dense(3, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XzxT70hRNi3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Meng-compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQNad7uwRNjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Melatih Model\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "history = model.fit(X_train, \n",
        "                    y_train, \n",
        "                    epochs=epochs, \n",
        "                    batch_size=batch_size, \n",
        "                    verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11QYbz_7RNjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot Akurasi dan Loss\n",
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.title('Akurasi dan Loss Training')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niHoCECKW3dY",
        "colab_type": "text"
      },
      "source": [
        "### Sentimen Fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pRYel3GW4LI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fungsi sentimen fuzzy\n",
        "def single_fuzzy_sentiment_biner(txt):\n",
        "  x=[txt]\n",
        "  print(x)\n",
        "  x=tokenizer.texts_to_sequences(x)\n",
        "  x=pad_sequences(x, maxlen=200, padding='post')\n",
        "  predictions=model.predict(x)\n",
        "  probability=predictions[0].tolist()\n",
        "  fuzzy_sentiment=0.5-((1/2)*probability[0])+((1/2)*probability[1])\n",
        "  return fuzzy_sentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6TpYNXXRNj1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Menjalankan fungsi sentimen fuzzy\n",
        "print(data.text[3])\n",
        "print('Sentimen Fuzzy:')\n",
        "single_fuzzy_sentiment_biner(data.text[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PvPHv8DXLAT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fungsi uji sentimen kalimat(positif atau negatif)[STANDAR]\n",
        "def sentimen_analysis(x):\n",
        "  x=[x]\n",
        "  x=token.texts_to_sequences(x)\n",
        "  x=pad_sequences(x, maxlen=200, padding='post')\n",
        "  return model.predict_classes(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lydxiJZvXNjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Menjalankan fungsi sentimen fuzzy dan standar\n",
        "data.text[3]\n",
        "print(x)\n",
        "print('Sentimen')\n",
        "print(data.airline_sentiment[3])\n",
        "print('Sentimen analisis dengan CNN')\n",
        "print(sentimen_analysis(x))\n",
        "print('Fuzzy sentimen analisis dengan CNN')\n",
        "single_fuzzy_sentiment_biner(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QZp2qDCXQVK",
        "colab_type": "text"
      },
      "source": [
        "### Evaluasi Sentimen Fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEuMBeIUXVJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mendefinisikan fungsi fuzzy sentimen pada satu kolom(banyak kalimat)\n",
        "def fuzzy_sentimen_column(bahan):\n",
        "  fuzzy_sentimen_kolom=[]\n",
        "  for kalimat in bahan:\n",
        "    fuzzy_sentimen_kolom.append(single_fuzzy_sentiment_biner(kalimat))\n",
        "  return fuzzy_sentimen_kolom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oLZKHLEXWwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mendefinisikan fungsi uji sentimen pada satu kolom(banyak kalimat)\n",
        "def sentimen_column(bahan):\n",
        "  x=token.texts_to_sequences(bahan)\n",
        "  x=pad_sequences(x, maxlen=input_length, padding='post')\n",
        "  word_sentimen=model.predict_classes(x)\n",
        "  word_sentimen=gabung_sublist(word_sentimen)\n",
        "  return word_sentimen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igFrfwU6XYQq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fungsi menggabung sublist\n",
        "def gabung_sublist(list1):\n",
        "  list2=[]\n",
        "  for i in list1:\n",
        "    list2.append(float(i))\n",
        "  return list2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5v3d-zZXaos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mendefinisikan pengurangan dua list\n",
        "def substract_two_list(list1,list2):\n",
        "  difference = []\n",
        "  zip_object = zip(list1, list2)\n",
        "  for list1_i, list2_i in zip_object:\n",
        "    difference.append(list1_i-list2_i)\n",
        "  return difference"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vbl60SbZXcgh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Menghitung jarak euclid vektor sentimen(asli) dan prediksi CNN dan prediksi fuzzy sentimen\n",
        "bahan=data.text\n",
        "hasil1=fuzzy_sentimen_column(bahan)\n",
        "squared_hasil1 = [number ** 2 for number in hasil1]\n",
        "print(squared_hasil1)\n",
        "hasil2=sentimen_column(bahan)\n",
        "squared_hasil2 = [number ** 2 for number in hasil2]\n",
        "print(squared_hasil2)\n",
        "sentimencoba=imdb_data.sentiment[:100]\n",
        "squared_sentimencoba = [number ** 2 for number in sentimencoba]\n",
        "print(squared_sentimencoba)\n",
        "print(abs(sum(substract_two_list(squared_hasil1,squared_sentimencoba))))\n",
        "print(abs(sum(substract_two_list(squared_hasil2,squared_sentimencoba))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWZXb-tzXfkZ",
        "colab_type": "text"
      },
      "source": [
        "### Kesimpulan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIkMDDn4XiBm",
        "colab_type": "text"
      },
      "source": [
        "Fuzzy Sentimen Analisis menyajikan sentimen sebuah kalimat dalam bentuk fuzzy atau derajat sentimen sebuah kalimat(tidak pasti[0 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIkhxjHLRNkA",
        "colab_type": "text"
      },
      "source": [
        "**Akhir dokumen**\n",
        "\n",
        "---"
      ]
    }
  ]
}